{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "990328f7",
      "metadata": {
        "id": "990328f7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "86dba385",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86dba385",
        "outputId": "80935e2f-c1de-4171-8cb7-5142e00514eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fc675756",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc675756",
        "outputId": "c99747c1-3cea-4a64-ac21-663f0fdc0d9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x78a44f1a52f0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "614c00e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "614c00e7",
        "outputId": "ac50170b-3897-4569-c87e-6513339387e7"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/fashion-mnist_train.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-944944160.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/fashion-mnist_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/fashion-mnist_train.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/content/fashion-mnist_train.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eadbed8",
      "metadata": {
        "id": "1eadbed8"
      },
      "outputs": [],
      "source": [
        "# Create a 4x4 grid of images\n",
        "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
        "fig.suptitle(\"First 16 Images\", fontsize=16)\n",
        "\n",
        "# Plot the first 16 images from the dataset\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    img = df.iloc[i, 1:].values.reshape(28, 28)  # Reshape to 28x28\n",
        "    ax.imshow(img)  # Display in grayscale\n",
        "    ax.axis('off')  # Remove axis for a cleaner look\n",
        "    ax.set_title(f\"Label: {df.iloc[i, 0]}\")  # Show the label\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to fit the title\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30da9392",
      "metadata": {
        "id": "30da9392"
      },
      "outputs": [],
      "source": [
        "x = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cea9e166",
      "metadata": {
        "id": "cea9e166"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec49c719",
      "metadata": {
        "id": "ec49c719"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0065b19c",
      "metadata": {
        "id": "0065b19c"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = torch.tensor(features, dtype = torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype = torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.features[index], self.labels[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4329a4d",
      "metadata": {
        "id": "b4329a4d"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b722266d",
      "metadata": {
        "id": "b722266d"
      },
      "outputs": [],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d395779",
      "metadata": {
        "id": "9d395779"
      },
      "outputs": [],
      "source": [
        "test_dataset = CustomDataset(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deeb153b",
      "metadata": {
        "id": "deeb153b"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True, pin_memory = True)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False, pin_memory = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bOslwq0EHFgh",
      "metadata": {
        "id": "bOslwq0EHFgh"
      },
      "outputs": [],
      "source": [
        "class myNN(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, num_hidden_layers, neurons_per_layer):\n",
        "    super().__init__()\n",
        "    layers = []\n",
        "    for i in range(num_hidden_layers):\n",
        "        layers.append(nn.Linear(input_dim, neurons_per_layer))\n",
        "        layers.append(nn.BatchNorm1d(neurons_per_layer))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(p = 0.3))\n",
        "        input_dim = neurons_per_layer\n",
        "    layers.append(nn.Linear(input_dim, output_dim))\n",
        "    self.model = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YI3YZ6tlGo66",
      "metadata": {
        "id": "YI3YZ6tlGo66"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "\n",
        "  #hyperparameters to be tuned\n",
        "  num_hidden_layers = trial.suggest_int('num_hidden_layers', 1, 5)\n",
        "  neurons_per_layer = trial.suggest_int('neurons_per_layer', 8, 128, step = 8)\n",
        "\n",
        "  #model init\n",
        "  input_dim = 784\n",
        "  output_dim = 10\n",
        "\n",
        "  model = myNN(input_dim, output_dim, num_hidden_layers, neurons_per_layer)\n",
        "  model = model.to(device)\n",
        "\n",
        "  #params init\n",
        "  epochs = 100\n",
        "  lr = 1e-1\n",
        "\n",
        "  #optimiser selection\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr= lr, weight_decay = 1e-4)\n",
        "\n",
        "  #training loop\n",
        "  for epoch in range(epochs):\n",
        "    for features, labels in train_loader:\n",
        "        features, labels = features.to(device), labels.to(device)\n",
        "        y_pred = model(features)\n",
        "        loss = criterion(y_pred, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "  #evaluation\n",
        "  model.eval()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "      for batch_features, batch_labels in test_loader:\n",
        "          batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "          output = model(batch_features)\n",
        "          _, predicted = torch.max(output, 1)\n",
        "          correct = correct + (predicted == batch_labels).sum().item()\n",
        "          total += batch_labels.shape[0]\n",
        "      accuracy = correct / total\n",
        "\n",
        "  return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QdkpDs_HmQqA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdkpDs_HmQqA",
        "outputId": "e967ce29-99ab-4da0-9fe5-84ad57e4af71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IrK2ao8WJ1Hl",
      "metadata": {
        "id": "IrK2ao8WJ1Hl"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "study = optuna.create_study(direction = 'maximize')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yUrgwWdAJ-0J",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yUrgwWdAJ-0J",
        "outputId": "4c0b6481-f498-4182-d6ff-a96712b9346c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-12-18 11:21:46,923] Trial 0 finished with value: 0.8565 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 32}. Best is trial 0 with value: 0.8565.\n",
            "[I 2025-12-18 11:29:03,887] Trial 1 finished with value: 0.8868333333333334 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 80}. Best is trial 1 with value: 0.8868333333333334.\n",
            "[I 2025-12-18 11:33:14,200] Trial 2 finished with value: 0.847 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 16}. Best is trial 1 with value: 0.8868333333333334.\n",
            "[I 2025-12-18 11:40:26,040] Trial 3 finished with value: 0.8564166666666667 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 32}. Best is trial 1 with value: 0.8868333333333334.\n",
            "[I 2025-12-18 11:46:37,843] Trial 4 finished with value: 0.8915833333333333 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 112}. Best is trial 4 with value: 0.8915833333333333.\n",
            "[I 2025-12-18 11:54:46,977] Trial 5 finished with value: 0.8743333333333333 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 56}. Best is trial 4 with value: 0.8915833333333333.\n",
            "[I 2025-12-18 11:58:54,816] Trial 6 finished with value: 0.8515833333333334 and parameters: {'num_hidden_layers': 1, 'neurons_per_layer': 16}. Best is trial 4 with value: 0.8915833333333333.\n",
            "[I 2025-12-18 12:05:03,432] Trial 7 finished with value: 0.8878333333333334 and parameters: {'num_hidden_layers': 3, 'neurons_per_layer': 88}. Best is trial 4 with value: 0.8915833333333333.\n",
            "[I 2025-12-18 12:13:09,304] Trial 8 finished with value: 0.8779166666666667 and parameters: {'num_hidden_layers': 5, 'neurons_per_layer': 56}. Best is trial 4 with value: 0.8915833333333333.\n",
            "[I 2025-12-18 12:20:17,767] Trial 9 finished with value: 0.881 and parameters: {'num_hidden_layers': 4, 'neurons_per_layer': 56}. Best is trial 4 with value: 0.8915833333333333.\n"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}