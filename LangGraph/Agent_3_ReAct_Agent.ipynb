{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2d79716",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, TypedDict, Annotated\n",
    "from langgraph.graph import START, StateGraph, END\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import BaseMessage, ToolMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a3a3558",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages : Annotated[Sequence[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0852be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a : int, b: int):\n",
    "    \"\"\"This addition function takes 2 integers as input and returns their sum as output\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def subtract(a : int, b: int):\n",
    "    \"\"\"This subtract function takes 2 integers as input and returns their difference as output\"\"\"\n",
    "    return a - b\n",
    "\n",
    "@tool\n",
    "def multiply(a : int, b: int):\n",
    "    \"\"\"This multiply function takes 2 integers as input and returns their product as output\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4b75101",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add, subtract, multiply]\n",
    "model = ChatOllama(model=\"llama3.2\").bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8f356e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_call(state : AgentState) -> AgentState:\n",
    "    # Explicitly telling the model NOT to talk when calling tools\n",
    "    system_prompt = SystemMessage(\n",
    "        content = \"You are a helpful assistant. \"\n",
    "                  \"If you need to use a tool, output the tool call only without preamble.\"\n",
    "    )\n",
    "    response = model.invoke([system_prompt] + state['messages'])\n",
    "    return {\"messages\" : [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "18565b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state : AgentState) -> str:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5ccc817",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"my_agent\", model_call)\n",
    "graph.add_edge(START, \"my_agent\")\n",
    "tool_node = ToolNode(tools = tools)\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "graph.add_conditional_edges(\n",
    "    \"my_agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"end\" : END,\n",
    "        \"continue\" : \"tools\"\n",
    "    }\n",
    ")\n",
    "graph.add_edge(\"tools\", \"my_agent\")\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f6a20b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stream(stream):\n",
    "    for s in stream:\n",
    "        # 'values' mode returns the full state at each step\n",
    "        message = s[\"messages\"][-1]\n",
    "        message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "40f05c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 40 + 12. Call that value x. Multiply x by 6 and show as final output. Also tell me a joke please.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (bf079c4f-0623-4928-8a97-e72f661690cb)\n",
      " Call ID: bf079c4f-0623-4928-8a97-e72f661690cb\n",
      "  Args:\n",
      "    a: 52\n",
      "    b: 6\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "312\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "Because it was two-tired! (get it?)\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": [(\"user\", \"Add 40 + 12. Call that value x. Multiply x by 6 and show as final output. Also tell me a joke please.\")]}\n",
    "print_stream(app.stream(inputs, stream_mode=\"values\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
